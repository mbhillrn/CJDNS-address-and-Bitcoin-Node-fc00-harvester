# AUTOGENERATED from harvest.sh (run_phase4_onetry.sh)
# Part 4 - Continue from Part 3


frontier_stage_into_db_and_newhosts() {
  # Frontier must behave like NodeStore new hits: add to DB AND stage into PHASE4_NEW_HOSTS_FILE for THIS run.
  # Requires: lib/frontier.sh (cjdh_frontier_expand), DB_PATH, and (optional) PHASE4_NEW_HOSTS_FILE.

  local enable="${FRONTIER_ENABLE:-no}"
  local every="${FRONTIER_EVERY_N_SCANS:-0}"
  local timeout_ms="${FRONTIER_TIMEOUT_MS:-${FRONTIER_TIMEOUT_MS_DEFAULT:-2000}}"
  local loop_num="${1:-0}"

  # Gate
  if [[ "$enable" != "yes" ]]; then
    return 0
  fi
  if [[ "$every" =~ ^[0-9]+$ ]] && (( every > 0 )); then
    if [[ "$loop_num" =~ ^[0-9]+$ ]] && (( loop_num % every != 0 )); then
      log_info "Frontier gate: enable=yes every=$every loop=$loop_num => skip"
      return 0
    fi
  else
    # every=0 disables frontier
    log_info "Frontier gate: every=0 => off"
    return 0
  fi

  # Must have the primitive
  if ! command -v cjdh_frontier_expand >/dev/null 2>&1; then
    log_warn "Frontier: cjdh_frontier_expand not found (lib/frontier.sh not sourced?)"
    return 0
  fi

  log_info "Frontier: running (timeout_ms=$timeout_ms)"

  local tmpf="$TMPDIR/frontier.out.$$"
  : >"$tmpf"
  local newf="$TMPDIR/frontier.newhosts.$$"
  : >"$newf"

  # Capture stdout (IPs) to file; frontier progress goes to stderr by design.
  
local _t0=${SECONDS:-0}
cjdh_frontier_expand "${CJDNS_ADMIN_ADDR:-127.0.0.1}" "${CJDNS_ADMIN_PORT:-11234}" "$timeout_ms" >"$tmpf" 2> >(awk '{ printf "[%s]   frontier: %s\n", strftime("%Y-%m-%d %H:%M:%S"), $0; fflush() }' >&2) || true
log_info "Frontier: elapsed=$(( ${SECONDS:-0} - _t0 ))s"

  if [[ ! -s "$tmpf" ]]; then
    log_info "Frontier: no addresses discovered"
    rm -f "$tmpf" 2>/dev/null || true
    return 0
  fi

  local total=0 new=0 existing=0
  while IFS= read -r host; do
    host="$(canon_host "$host")"
    [[ -n "$host" ]] || continue

    total=$((total+1))

    local now inserted
    now="$(date +%s)"
    inserted="$(sqlite3 "$DB_PATH" <<SQL 2>/dev/null || echo 0
.parameter init
.parameter set @host '$host'
.parameter set @now $now
INSERT OR IGNORE INTO master(host, first_seen_ts, last_seen_ts, source_flags)
VALUES(@host,@now,@now,'frontier');
SELECT changes();
SQL
)"

    if [[ "$inserted" == "1" ]]; then
      # record truly-new frontier inserts for visibility
      printf "%s\n" "$host" >>"$newf"
      new=$((new+1))
      # Stage into candidates for THIS run (same behavior as nodestore new hits)
      if [[ -n "${PHASE4_NEW_HOSTS_FILE:-}" ]]; then
        printf "%s\n" "$host" >>"$PHASE4_NEW_HOSTS_FILE"
      fi
    else
      existing=$((existing+1))
      db_upsert_master "$host" "frontier"
    fi
  done <"$tmpf"

  rm -f "$tmpf" 2>/dev/null || true
  log_info "Frontier: done total=$total new=$new existing=$existing"
  if [[ -s "$newf" ]]; then
    log_info "Frontier: new hosts this run:"
    while IFS= read -r _h; do log_info "Frontier NEW: $_h"; done <"$newf"
  fi
}

run_phase4() {
  log_info "Phase 4 run (ingest + batch onetry attempts)."


  finalize_stale_attempts 600 || true

  load_conf
  db_init_schema



  # Smart Mode: enforce stable runtime defaults (do NOT rely on whatever the normal wizard last saved)
  if [[ "${SMART_MODE:-no}" == "yes" ]]; then
    apply_smart_defaults_runtime
    smart_db_init_schema
  fi

  local loop_num
  local already_connected=0
  loop_num="$(db_next_loop_num)"
  tmp_reset_loop
  RUN_START_LOOP_NUM="${RUN_START_LOOP_NUM:-$loop_num}"

  echo
    echo
    print_box "DATABASE STATUS"
    db_counts

  # ========================================================================
  # OPTIMIZED: Single getpeerinfo call for display + pre-snapshot
  # ========================================================================
  print_section "Capturing Core peers (pre-snapshot)"
  # Status to stderr; keep stdout clean for JSON/data.
  show_progress "Fetching getpeerinfo" >&2
  CORE_PEERS_JSON_PRE="$(run_cmd_capture_json "getpeerinfo_pre" bash -lc "$CLI getpeerinfo")"
  if ! cjdh_json_must_start "getpeerinfo_pre" "$CORE_PEERS_JSON_PRE"; then
    log_warn "getpeerinfo_pre not JSON; skipping Core pre-snapshot for this loop."
    CORE_PEERS_JSON_PRE="[]"
  fi
  echo " done" >&2
  # Build pre-snapshot from captured JSON
  pre="$(echo "$CORE_PEERS_JSON_PRE" | jq -r '.[] | select(.network=="cjdns") | .addr' | while IFS= read -r raw; do canon_host "$(cjdns_host_from_maybe_bracketed "$raw")"; done | sort -u)"
  local pre_n
  pre_n="$(printf '%s\n' "$pre" | sed '/^$/d' | wc -l | awk '{print $1}')"
  echo "Core peers (cjdns) pre-snapshot: $pre_n"

  # ---- Dashboard blocks (router/core) - Core uses cached JSON ----
  probe_router_status
  
  # Display Core peers using cached JSON (instead of calling getpeerinfo again)
  if [[ "$SHOW_CORE_PEERS" == "yes" ]]; then
    print_section "Bitcoin Core (cjdns)"
    
    local total inb outb
    total="$(echo "$CORE_PEERS_JSON_PRE" | jq '[.[] | select(.network=="cjdns")] | length')"
    inb="$(echo "$CORE_PEERS_JSON_PRE" | jq '[.[] | select(.network=="cjdns" and .inbound==true)] | length')"
    outb="$(echo "$CORE_PEERS_JSON_PRE" | jq '[.[] | select(.network=="cjdns" and .inbound==false)] | length')"
    
    echo "  Connected=$total  inbound=$inb outbound=$outb"
    
    echo "$CORE_PEERS_JSON_PRE" | jq -r '
      .[]
      | select(.network=="cjdns")
      | (if .inbound then "IN" else "OUT" end) + "\t" + .addr
    ' | while IFS=$'\t' read -r dir addr; do
      host="$(canon_host "$(cjdns_host_from_maybe_bracketed "$addr")")"
        if [[ "$dir" == "OUT" ]]; then
          printf "    ${C_PINK}%-3s${C_RESET} %s\n" "$dir" "$host"
        else
          printf "    ${C_NAVY}%-3s${C_RESET} %s\n" "$dir" "$host"
        fi
    done | head -n 200
  fi

  # Harvest NodeStore -> MASTER, and collect "new this run" into file
  PHASE4_NEW_HOSTS_FILE="$TMPDIR/harvest.phase4.newhosts.$$"
  export PHASE4_NEW_HOSTS_FILE
  # Frontier: stage discovered addresses into master + PHASE4_NEW_HOSTS_FILE so they get tried THIS run
  frontier_stage_into_db_and_newhosts "$loop_num" || true
  # BEGIN FRONTIER FORCE ONETRY
  # Frontier: force onetry for newly staged hosts THIS run.
  if [[ -n "${PHASE4_NEW_HOSTS_FILE:-}" && -s "$PHASE4_NEW_HOSTS_FILE" ]]; then
    sort -u -o "$PHASE4_NEW_HOSTS_FILE" "$PHASE4_NEW_HOSTS_FILE" 2>/dev/null || true
    _nnew="$(wc -l <"$PHASE4_NEW_HOSTS_FILE" 2>/dev/null || echo 0)"
    log_info "Frontier: forcing onetry for ${_nnew} newly discovered host(s)"
    while IFS= read -r _h; do
      [[ -n "${_h:-}" ]] || continue
      _h="$(canon_host "$_h")"
      [[ -n "${_h:-}" ]] || continue
      log_info "Frontier: onetry -> ${_h}"
      $CLI addnode "${_h}" onetry >/dev/null 2>&1 || true
    done <"$PHASE4_NEW_HOSTS_FILE"
  fi
  # END FRONTIER FORCE ONETRY

  ingest_nodestore_to_db
  ingest_remote_nodestore_to_db
  # Seed confirmed/master from addrman + current connected peers (NO nodestore confirmation)
  ingest_confirmed_sources

  echo
  echo "DB counts (after ingest):"
  db_counts

  # Build candidate list from "new this run" file:
  # - skip blanks
  # - skip anything already connected pre-snapshot
  # - skip anything already confirmed in DB
  local candidates_file="$TMPDIR/harvest.phase4.candidates.$$"
  : >"$candidates_file"

  if [[ -s "$PHASE4_NEW_HOSTS_FILE" ]]; then
    while IFS= read -r host; do
      [[ -n "$host" ]] || continue



        host="$(canon_host "$host")"
        [[ -n "$host" ]] || continue
      # already connected?
      if printf '%s\n' "$pre" | grep -qxF "$host"; then
        continue
      fi

      # already confirmed?
      if [[ "$(db_query is_conf "SELECT 1 FROM confirmed WHERE host='$host' LIMIT 1;")" == "1" ]]; then
        continue
      fi

      printf '%s\n' "$host" >>"$candidates_file"
    done <"$PHASE4_NEW_HOSTS_FILE"
  fi

  local total_candidates
  total_candidates="$(sed '/^$/d' "$candidates_file" | wc -l | awk '{print $1}')"


  echo
  # If there are no new candidates from this run, optionally do a retry pass.
  # Default behavior remains: do nothing unless knobs are enabled.
  local cand_count
  cand_count="$(grep -cve '^\s*$' "$candidates_file" 2>/dev/null || echo 0)"

  local do_retry_tried="no" do_recheck_confirmed="no"
  if [[ "${RETRY_TRIED_EVERY_LOOPS:-0}" =~ ^[0-9]+$ ]] && (( RETRY_TRIED_EVERY_LOOPS > 0 )) && (( (loop_num - RUN_START_LOOP_NUM + 1) % RETRY_TRIED_EVERY_LOOPS == 0 )); then
    do_retry_tried="yes"
  fi
  if [[ "${RECHECK_CONFIRMED_EVERY_LOOPS:-0}" =~ ^[0-9]+$ ]] && (( RECHECK_CONFIRMED_EVERY_LOOPS > 0 )) && (( (loop_num - RUN_START_LOOP_NUM + 1) % RECHECK_CONFIRMED_EVERY_LOOPS == 0 )); then
    do_recheck_confirmed="yes"
  fi

  if { [[ "$do_retry_tried" == "yes" ]] || [[ "$do_recheck_confirmed" == "yes" ]]; }; then
    echo
    echo "Retry policy: loop_num=$loop_num  retry_tried=$do_retry_tried  recheck_confirmed=$do_recheck_confirmed"

    # Determine retry batch sizes.
    # Confirmed retry cap precedence:
    #   1) RECHECK_CONFIRMED_MAX_PER_LOOP (if >0)
    #   2) MAX_ATTEMPTS_PER_LOOP (if >0)
    #   3) 0 => no cap
    local batch_confirm="${RECHECK_CONFIRMED_MAX_PER_LOOP:-0}"
    [[ "$batch_confirm" =~ ^[0-9]+$ ]] || batch_confirm=0
    if (( batch_confirm <= 0 )); then
      batch_confirm="${MAX_ATTEMPTS_PER_LOOP:-0}"
      [[ "$batch_confirm" =~ ^[0-9]+$ ]] || batch_confirm=0
    fi

    # For master retry, use MAX_ATTEMPTS_PER_LOOP if set; else 0=no cap.
    local batch_master="${MAX_ATTEMPTS_PER_LOOP:-0}"
    [[ "$batch_master" =~ ^[0-9]+$ ]] || batch_master=0

    if [[ "$do_recheck_confirmed" == "yes" ]]; then
      if (( batch_confirm > 0 )); then
        echo "  Retry pass: CONFIRMED (up to $batch_confirm addresses)"
      else
        echo "  Retry pass: CONFIRMED (no cap)"
      fi
      pick_confirmed_candidates_from_db "$batch_confirm" >>"$candidates_file" 2>/dev/null || true
    fi

    if [[ "$do_retry_tried" == "yes" ]]; then
      if (( batch_master > 0 )); then
        echo "  Retry pass: MASTER eligible (up to $batch_master addresses)"
      else
        echo "  Retry pass: MASTER eligible (no cap)"
      fi
      pick_candidates_from_db "$batch_master" >>"$candidates_file" 2>/dev/null || true
    fi

    # de-dupe candidates_file
    sort -u "$candidates_file" -o "$candidates_file" 2>/dev/null || true


    fi

  # ========================================================================
  # OPTIMIZED: Reuse pre-snapshot for filtering (no redundant getpeerinfo call)
  # ========================================================================
  local connected_now deny_now tmp_filtered removed
  connected_now="$TMPDIR/harvest.connected_now.$$"
  deny_now="$TMPDIR/harvest.deny_now.$$"
  tmp_filtered="$TMPDIR/harvest.candidates.filtered.$$"
  removed=0

  # Build connected host set from pre-snapshot (already captured above)
  printf '%s\n' "$pre" | sort -u >"$connected_now" || true


    # ---- Smart Mode: append 10 MASTER picks each loop (with run-based cooldowns) ----
    smart_attempted_file=""
    if [[ "${SMART_MODE:-no}" == "yes" ]]; then
      smart_reset_state_if_first_loop "$loop_num"
      smart_tick_cooldowns
      smart_attempted_file="$TMPDIR/harvest.smart_master_attempted.$$"
      smart_pick_master_10 "$connected_now" "$smart_attempted_file" || true
      if [[ -f "$smart_attempted_file" ]]; then
        local n_picks
        n_picks="$(awk 'NF{c++} END{print c+0}' "$smart_attempted_file" 2>/dev/null || true)"
        n_picks="$(num_sanitize "$(printf '%s' "$n_picks" | head -n 1)")"
        echo "Smart Mode: master_retry_picks=$n_picks cursor=$(smart_get_cursor)"
        if (( n_picks > 0 )); then
            printf "${C_DIM}Smart Mode picks this loop:${C_RESET}\n"
          sed 's/^/  • /' "$smart_attempted_file"
        fi
      fi
      if [[ -s "$smart_attempted_file" ]]; then
        cat "$smart_attempted_file" >>"$candidates_file"
        sort -u "$candidates_file" -o "$candidates_file" 2>/dev/null || true
      fi
    fi

  : >"$deny_now"
  if [[ -s "$connected_now" ]]; then
    cat "$connected_now" >>"$deny_now"
    while IFS= read -r h; do
      python3 - "$h" <<'PYN' 2>/dev/null || true
import sys, ipaddress
try:
    print(ipaddress.ip_address(sys.argv[1]).compressed)
except Exception:
    pass
PYN
    done <"$connected_now" >>"$deny_now"
  fi

  # Add our own cjdns address (raw + normalized) so we never onetry ourselves.
  myip="$(
    run_cmd_capture "getnetworkinfo" bash -lc "$CLI getnetworkinfo" \
      | jq -r '.localaddresses[]? | select(.address|startswith("fc")) | .address' \
      | head -n1
  )" || true
    if [[ -n "${myip:-}" ]]; then
      # Add raw + normalized self IP to deny list (do NOT print to screen)
      echo "$myip" >>"$deny_now"
      python3 - "$myip" <<'PYN' 2>/dev/null >>"$deny_now" || true
import sys, ipaddress
try:
    print(ipaddress.ip_address(sys.argv[1]).compressed)
except Exception:
    pass
PYN
    fi

  sort -u "$deny_now" -o "$deny_now" || true

  # Show candidate list before filtering (trimmed)
  local pre_list_n
  pre_list_n="$(grep -cve '^\s*$' "$candidates_file" 2>/dev/null || echo 0)"
  pre_list_n="$(num_sanitize "$pre_list_n")"
  echo "Candidates (pre-filter): $pre_list_n"
  if (( pre_list_n > 0 )); then
    sed -n '1,80p' "$candidates_file" | sed 's/^/  • /'
    if (( pre_list_n > 80 )); then echo "  … (truncated; showing first 80)"; fi
  fi

  # Filter candidates: skip if raw OR normalized form is in deny list
  before_n="$(grep -cve '^\s*$' "$candidates_file" 2>/dev/null || echo 0)"
    before_n="$(num_sanitize "$before_n")"
  : >"$tmp_filtered"
  while IFS= read -r cand; do
    [[ -n "${cand//[[:space:]]/}" ]] || continue

    cand_norm="$(python3 - "$cand" <<'PYN' 2>/dev/null || true
import sys, ipaddress
try:
    print(ipaddress.ip_address(sys.argv[1]).compressed)
except Exception:
    pass
PYN
)"
    if grep -qxF "$cand" "$deny_now" 2>/dev/null; then
      continue
    fi
    if [[ -n "${cand_norm:-}" ]] && grep -qxF "$cand_norm" "$deny_now" 2>/dev/null; then
      continue
    fi
    echo "$cand" >>"$tmp_filtered"
  done <"$candidates_file"

  after_n="$(grep -cve '^\s*$' "$tmp_filtered" 2>/dev/null || true)"
  after_n="$(num_sanitize "${after_n:-0}")"
  # Post-filter visibility (trimmed)
  echo "Candidates (post-filter): $after_n"
  if (( after_n > 0 )); then
    sed -n '1,80p' "$tmp_filtered" | sed 's/^/  • /'
    if (( after_n > 80 )); then echo "  … (truncated; showing first 80)"; fi
  fi
  removed=$(( before_n - after_n ))
    # Show exactly which candidates were filtered out, and why.
    if (( removed > 0 )); then
        printf "  ${C_DIM}Filtered candidates:${C_RESET}\n"

      # Compare original candidates_file vs tmp_filtered to list removed hosts.
      local _cand_s _kept_s _rm_s
      _cand_s="$TMPDIR/harvest.cand.sorted.$$"
      _kept_s="$TMPDIR/harvest.kept.sorted.$$"
      _rm_s="$TMPDIR/harvest.removed.$$"

      sed '/^\s*$/d' "$candidates_file" | sort -u >"$_cand_s" 2>/dev/null || true
      sed '/^\s*$/d' "$tmp_filtered"    | sort -u >"$_kept_s" 2>/dev/null || true
      comm -23 "$_cand_s" "$_kept_s" >"$_rm_s" 2>/dev/null || true

      # Counters so the summary line is truthful (CONNECTED vs SELF vs DENY(normalization))
      local removed_self=0 removed_connected=0 removed_deny=0

      while IFS= read -r h; do
        [[ -n "$h" ]] || continue

        # Reason bucketing:
        #   SELF: matches our myip raw or normalized
        #   CONNECTED: currently connected in Core (raw or normalized)
        #   DENY: otherwise in deny set (normalized collision, etc.)
        if [[ -n "${myip:-}" ]] && [[ "$h" == "$myip" ]]; then
          echo "    - $h  (SELF)"
          removed_self=$((removed_self+1))
          continue
        fi

        if [[ -n "${myip:-}" ]]; then
          myip_norm="$(python3 - "$myip" <<'PYN' 2>/dev/null || true
import sys, ipaddress
try:
    print(ipaddress.ip_address(sys.argv[1]).compressed)
except Exception:
    pass
PYN
)"
          if [[ -n "${myip_norm:-}" ]] && [[ "$h" == "$myip_norm" ]]; then
            echo "    - $h  (SELF)"
            removed_self=$((removed_self+1))
            continue
          fi
        fi

        if [[ -f "$connected_now" ]] && grep -qxF "$h" "$connected_now" 2>/dev/null; then
          echo "    - $h  (CONNECTED)"
          removed_connected=$((removed_connected+1))
          continue
        fi

        echo "    - $h  (DENY)"
        removed_deny=$((removed_deny+1))
      done <"$_rm_s"

      rm -f "$_cand_s" "$_kept_s" "$_rm_s" 2>/dev/null || true

      # Make the removal summary accurate (this fixes your 12 vs 14 confusion)
      echo "  Filtered candidates: removed=$removed (connected=$removed_connected self=$removed_self deny=$removed_deny)"
      already=$removed
    fi

  mv -f "$tmp_filtered" "$candidates_file"
  if (( removed > 0 )); then
  already_connected=$(( ${already_connected:-0} + removed ))
  fi

  rm -f "$connected_now" "$deny_now" "$tmp_filtered" 2>/dev/null || true

    printf "${C_DIM}Attempting candidates...${C_RESET}"
  local total_now
  total_now="$(grep -cve '^\s*$' "$candidates_file" 2>/dev/null || true)"
  [[ "$total_now" =~ ^[0-9]+$ ]] || total_now=0
  if (( total_now == 0 )); then
    echo "  (none)"
  fi

  local attempted="$TMPDIR/harvest.phase4.attempted.$$"
  local already_connected=0
  : >"$attempted"

    local ok=0 fail=0 already=0


  local tried=0 limit="$MAX_ATTEMPTS_PER_LOOP"
  while IFS= read -r host; do
    [[ -n "$host" ]] || continue

    if [[ "$limit" =~ ^[0-9]+$ ]] && (( limit > 0 )) && (( tried >= limit )); then
      break
    fi

      echo "  • $host"
      printf '%s\n' "$host" >>"$attempted"

      # Attempt with verify window (ping informational only; must NOT gate)
      if attempt_one_host "$host"; then
        ok=$((ok+1))
      else
        fail=$((fail+1))
      fi

    tried=$((tried+1))
    if [[ "$ONETRY_GAP_SEC" =~ ^[0-9]+$ ]] && (( ONETRY_GAP_SEC > 0 )); then
      sleep "$ONETRY_GAP_SEC"
    fi
  done <"$candidates_file"

  # After last onetry, wait before post-snapshot
  local settle="${ONETRY_BATCH_SETTLE_SEC:-3}"
[[ "$settle" =~ ^[0-9]+$ ]] || settle=3
echo "Waiting ${settle}s before Core post-snapshot diff (batch confirm)"
sleep "$settle"

  # Post-snapshot
  local post
  post="$(core_cjdns_connected_hosts || true)"

  echo
    print_section "Core Peer Diff (post - pre)"
  new_hosts="$(comm -13 <(printf '%s\n' "$pre" | sed '/^$/d' | sort -u) <(printf '%s\n' "$post" | sed '/^$/d' | sort -u))"


  # --- Batch confirmation/results ---
  # In batch mode, confirm only what actually appeared in Core peers (post-pre) AND was attempted.
  if ! should_inline_confirm; then
    # Build new_hosts = (post - pre)
    # Note: pre/post vars are newline lists; normalize+sort for comm.
    local pre_f="$TMPDIR/harvest.phase4.pre.$$"
    local post_f="$TMPDIR/harvest.phase4.post.$$"
    local new_f="$TMPDIR/harvest.phase4.new.$$"
    printf '%s\n' "$pre"  | sed '/^$/d' | sort -u >"$pre_f"
    printf '%s\n' "$post" | sed '/^$/d' | sort -u >"$post_f"
    comm -13 "$pre_f" "$post_f" >"$new_f" || true

    # Reset counters computed inline; we compute from batch outcome
    ok=0
    fail=0

    # Mark successes for attempted hosts that appear in new_hosts
    while IFS= read -r h; do
      [[ -n "$h" ]] || continue
      if grep -qxF "$h" "$attempted"; then
        db_upsert_confirmed "$h"
        db_upsert_master "$h" "onetry_connected"
        db_attempt_result_ok "$h"
        ok=$((ok+1))
      fi
    done <"$new_f"

    # Mark failures for attempted hosts that do NOT appear in new_hosts
    while IFS= read -r h; do
      [[ -n "$h" ]] || continue
      if ! grep -qxF "$h" "$new_f"; then
        db_attempt_result_fail "$h" "not_seen"
        fail=$((fail+1))
      fi
    done <"$attempted"

    rm -f "$pre_f" "$post_f" "$new_f"
  fi
  if [[ -n "$new_hosts" ]]; then
    echo "$new_hosts" | sed 's/^/  + /'
  else
    echo "  (none)"
  fi


    # Results are recorded per-host inside attempt_one_host() (confirmed + attempts).
    # We keep the Core peer diff above for visibility, but we do NOT re-write results here.

  # If something connected that we didn't attempt, surface it and record it
  if [[ -n "$new_hosts" ]]; then
    while IFS= read -r h; do
      [[ -n "$h" ]] || continue
      if ! grep -qxF "$h" "$attempted"; then
        printf "  "
        status_new_peer
        echo " (not in attempt list): $h"
        db_upsert_master "$h" "core_new"
        db_upsert_confirmed "$h"
      fi
    done <<<"$new_hosts"
  fi

  echo

    # Smart Mode: update cooldown state for the MASTER picks we attempted this loop
    if [[ "${SMART_MODE:-no}" == "yes" ]] && [[ -n "${smart_attempted_file:-}" ]] && [[ -f "$smart_attempted_file" ]]; then
      smart_update_results_from_batch "$smart_attempted_file" "${new_hosts:-}"
      rm -f "$smart_attempted_file" 2>/dev/null || true
    fi

    print_section "Phase 4 Summary"
  echo "  attempted=$tried  connected=$ok  not_seen=$fail  already_connected=$already"

  echo
    print_box "DATABASE STATUS (FINAL)"
  db_counts

  rm -f "$PHASE4_NEW_HOSTS_FILE" "$candidates_file" "$attempted"
}
